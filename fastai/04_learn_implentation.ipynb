{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6131) [Path('train/3/10.png'),Path('train/3/10000.png'),Path('train/3/10011.png'),Path('train/3/10031.png'),Path('train/3/10034.png'),Path('train/3/10042.png'),Path('train/3/10052.png'),Path('train/3/1007.png'),Path('train/3/10074.png'),Path('train/3/10091.png')...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()\n",
    "threes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2038, 784])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "valid_3_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'3').ls()])\n",
    "valid_3_tens = valid_3_tens.float()/255\n",
    "valid_7_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'7').ls()])\n",
    "valid_7_tens = valid_7_tens.float()/255\n",
    "valid_3_tens.shape,valid_7_tens.shape\n",
    "\n",
    "xs = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\n",
    "print(xs.shape)\n",
    "\n",
    "ys = tensor([0.0]*len(valid_3_tens) + [1.0]*len(valid_7_tens), dtype=torch.long).unsqueeze(1)\n",
    "print(ys.dtype)\n",
    "ys = ys.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ys = torch.empty(len(valid_3_tens) + len(valid_7_tens), 2)\n",
    "# ys[:,:] = 0.0\n",
    "# ys[0:len(valid_3_tens), 0] = 1.0\n",
    "# ys[len(valid_3_tens):, 1] = 1.0\n",
    "\n",
    "# ys = ys.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = list(zip(xs, ys))\n",
    "\n",
    "splits = RandomSplitter()(dset)\n",
    "\n",
    "ds = Datasets(items=dset, splits=splits)\n",
    "dl = DataLoader(ds.train, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicOptim:\n",
    "    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n",
    "\n",
    "    def get_params(self):\n",
    "        for o in self.params:\n",
    "            return L([o.weight for o in self.params if hasattr(o, 'weight') and o.weight.grad is not None])\n",
    "        \n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.get_params():\n",
    "            p.data -= p.grad.data * self.lr\n",
    "\n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.get_params():\n",
    "            p.grad = None\n",
    "            \n",
    "class Learner():\n",
    "\n",
    "    def __init__(self, dls, net, opt_func=None, loss_func=nn.CrossEntropyLoss(reduction='sum'), metrics=None):\n",
    "        self.net = net\n",
    "        self.dls = dls\n",
    "        self.loss_func = loss_func\n",
    "        self.metrics = metrics\n",
    "        \n",
    "        self.init()\n",
    "        self.opt = BasicOptim(self.net, lr=1e-5)\n",
    "        \n",
    "    def init_weights(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "    \n",
    "    def init(self):\n",
    "        self.net.apply(self.init_weights)\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        for d in self.dls.train:\n",
    "            \n",
    "            x, y = d[0]\n",
    "            \n",
    "            preds = self.net(x)\n",
    "        \n",
    "            input_ = preds.unsqueeze(1)\n",
    "            \n",
    "            loss = self.loss_func(preds, y)\n",
    "            loss.backward()\n",
    "    \n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "                \n",
    "    def train_model(self, epochs):\n",
    "        for i in range(epochs):\n",
    "            self.train_epoch()\n",
    "            print(self.validate_epoch())\n",
    "\n",
    "    \n",
    "    def validate_epoch(self):\n",
    "        accs = [self.metrics(self.net(ds[0][0]), ds[0][1]) for ds in self.dls.valid]\n",
    "        return round(torch.stack(accs).mean().item(), 4)\n",
    "\n",
    "    def fit(self):\n",
    "        lr = 1e-5\n",
    "\n",
    "        self.train_model(10)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5725\n",
      "0.6781\n",
      "0.7445\n",
      "0.7961\n",
      "0.8182\n",
      "0.8329\n",
      "0.8428\n",
      "0.8526\n",
      "0.8624\n",
      "0.8698\n"
     ]
    }
   ],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28, 30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30, 1)\n",
    ")\n",
    "\n",
    "def cross_entropy_loss(preds, targets):\n",
    "    preds = preds.softmax(dim=0)\n",
    "\n",
    "    loss = -(targets * preds.log()).sum() / len(preds)\n",
    "    return loss\n",
    "\n",
    "def mnist_loss(preds, targets):\n",
    "    return torch.where(targets==1, 1-preds, preds).mean()\n",
    "\n",
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds > 0.5) == yb\n",
    "    return correct.float().mean()\n",
    "\n",
    "l = Learner(dls = ds, net = simple_net, loss_func = mnist_loss, metrics=batch_accuracy)\n",
    "\n",
    "l.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2038, 784])\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        ...,\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]])\n"
     ]
    }
   ],
   "source": [
    "valid_3_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'3').ls()])\n",
    "valid_3_tens = valid_3_tens.float()/255\n",
    "valid_7_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'7').ls()])\n",
    "valid_7_tens = valid_7_tens.float()/255\n",
    "valid_3_tens.shape,valid_7_tens.shape\n",
    "\n",
    "xs = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\n",
    "print(xs.shape)\n",
    "\n",
    "ys = torch.empty([len(valid_3_tens) + len(valid_7_tens), 2], dtype=torch.long)\n",
    "ys[:,:] = 0.0\n",
    "ys[0:len(valid_3_tens),0] = 1.0\n",
    "ys[len(valid_3_tens):,1] = 1.0\n",
    "ys = ys.long()\n",
    "print(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = list(zip(xs, ys))\n",
    "\n",
    "splits = RandomSplitter()(dset)\n",
    "\n",
    "ds = Datasets(items=dset, splits=splits)\n",
    "dl = DataLoader(ds.train, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicOptim2D:\n",
    "    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n",
    "\n",
    "    def get_params(self):\n",
    "        for o in self.params:\n",
    "            return L([o.weight for o in self.params if hasattr(o, 'weight') and o.weight.grad is not None])\n",
    "        \n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.get_params():\n",
    "            p.data -= p.grad.data * self.lr\n",
    "\n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.get_params():\n",
    "            p.grad = None\n",
    "            \n",
    "class Learner2D():\n",
    "\n",
    "    def __init__(self, dls, net, opt_func=None, loss_func=nn.CrossEntropyLoss(reduction='sum'), metrics=None):\n",
    "        self.net = net\n",
    "        self.dls = dls\n",
    "        self.loss_func = loss_func\n",
    "        self.metrics = metrics\n",
    "        \n",
    "        self.init()\n",
    "        self.opt = BasicOptim2D(self.net, lr=1e-5)\n",
    "        \n",
    "    def init_weights(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "    \n",
    "    def init(self):\n",
    "        self.net.apply(self.init_weights)\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        for d in self.dls.train:\n",
    "            \n",
    "            x, y = d[0]\n",
    "            \n",
    "            preds = self.net(x)\n",
    "        \n",
    "            input_ = preds.unsqueeze(1)\n",
    "            \n",
    "            loss = self.loss_func(preds, y)\n",
    "            loss.backward()\n",
    "    \n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "                \n",
    "    def train_model(self, epochs):\n",
    "        for i in range(epochs):\n",
    "            self.train_epoch()\n",
    "            print(self.validate_epoch())\n",
    "\n",
    "    \n",
    "    def validate_epoch(self):\n",
    "        accs = [self.metrics(self.net(ds[0][0]), ds[0][1]) for ds in self.dls.valid]\n",
    "        return round(torch.stack(accs).mean().item(), 4)\n",
    "\n",
    "    def fit(self, epochs = 10):\n",
    "        lr = 1e-5\n",
    "\n",
    "        self.train_model(epochs)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5283\n",
      "0.5516\n",
      "0.5663\n",
      "0.5835\n",
      "0.5983\n",
      "0.6179\n",
      "0.6339\n",
      "0.6523\n",
      "0.6609\n",
      "0.6708\n",
      "0.6781\n",
      "0.6941\n",
      "0.6978\n",
      "0.7052\n",
      "0.7174\n",
      "0.731\n",
      "0.7469\n",
      "0.7555\n",
      "0.7678\n",
      "0.785\n",
      "0.7899\n",
      "0.8034\n",
      "0.8084\n",
      "0.8133\n",
      "0.8231\n",
      "0.8292\n",
      "0.8366\n",
      "0.8403\n",
      "0.8452\n",
      "0.8477\n",
      "0.8587\n",
      "0.8612\n",
      "0.8661\n",
      "0.871\n",
      "0.8735\n",
      "0.8759\n",
      "0.8808\n",
      "0.8833\n",
      "0.8882\n",
      "0.8894\n",
      "0.8907\n",
      "0.8956\n",
      "0.8993\n",
      "0.9005\n",
      "0.9042\n",
      "0.9066\n",
      "0.9091\n",
      "0.9115\n",
      "0.9128\n",
      "0.914\n",
      "0.914\n",
      "0.9152\n",
      "0.9165\n",
      "0.9189\n",
      "0.9189\n",
      "0.9201\n",
      "0.9201\n",
      "0.9201\n",
      "0.9226\n",
      "0.9238\n",
      "0.9251\n",
      "0.9263\n",
      "0.9263\n",
      "0.9287\n",
      "0.9324\n",
      "0.9337\n",
      "0.9337\n",
      "0.9337\n",
      "0.9349\n",
      "0.9361\n",
      "0.9361\n",
      "0.9361\n",
      "0.9386\n",
      "0.9398\n",
      "0.9398\n",
      "0.941\n",
      "0.941\n",
      "0.941\n",
      "0.9435\n",
      "0.9435\n",
      "0.9435\n",
      "0.9423\n",
      "0.9435\n",
      "0.9435\n",
      "0.9423\n",
      "0.9423\n",
      "0.9423\n",
      "0.9435\n",
      "0.9447\n",
      "0.9447\n",
      "0.9447\n",
      "0.9447\n",
      "0.9472\n",
      "0.9472\n",
      "0.9472\n",
      "0.9484\n",
      "0.9484\n",
      "0.9496\n",
      "0.9509\n",
      "0.9509\n"
     ]
    }
   ],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28, 30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30, 2)\n",
    ")\n",
    "\n",
    "def cross_entropy_loss(preds, targets):\n",
    "    preds = preds.softmax(dim=0)\n",
    "\n",
    "    loss = -(targets * preds.log()).sum() / len(preds)\n",
    "    return loss\n",
    "\n",
    "def mnist_loss(preds, targets):\n",
    "    return torch.where(targets==1, 1-preds, preds).mean()\n",
    "\n",
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds > 0.5) == yb\n",
    "    return correct.float().mean()\n",
    "\n",
    "l = Learner2D(dls = ds, net = simple_net, loss_func = cross_entropy_loss, metrics=batch_accuracy)\n",
    "\n",
    "l.fit(epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D all mnist numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST)\n",
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = torch.empty([0, 28, 28])\n",
    "ys = torch.empty([0, 10])\n",
    "for i in range(0, 10):\n",
    "    i_str = str(i)\n",
    "    valid_i_tens = torch.stack([tensor(Image.open(o)) \n",
    "                             for o in (path/'training'/i_str).ls()])\n",
    "    \n",
    "    valid_i_tens = valid_3_tens.float()/255\n",
    "\n",
    "    xs = torch.cat([xs, valid_i_tens])\n",
    "    \n",
    "    y = torch.empty([10])\n",
    "    y[:] = 0\n",
    "    y[i] = 1.0\n",
    "\n",
    "    ys = torch.cat([ys, y.repeat(valid_i_tens.shape[0], 1)])\n",
    "\n",
    "xs = xs.view(-1, 28*28)\n",
    "ys = ys.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = list(zip(xs, ys))\n",
    "\n",
    "splits = RandomSplitter()(dset)\n",
    "\n",
    "ds = Datasets(items=dset, splits=splits)\n",
    "dl = DataLoader(ds.train, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicOptim2D:\n",
    "    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n",
    "\n",
    "    def get_params(self):\n",
    "        for o in self.params:\n",
    "            return L([o.weight for o in self.params if hasattr(o, 'weight') and o.weight.grad is not None])\n",
    "        \n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.get_params():\n",
    "            p.data -= p.grad.data * self.lr\n",
    "\n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.get_params():\n",
    "            p.grad = None\n",
    "            \n",
    "class Learner2D():\n",
    "\n",
    "    def __init__(self, dls, net, opt_func=None, loss_func=nn.CrossEntropyLoss(reduction='sum'), metrics=None):\n",
    "        self.net = net\n",
    "        self.dls = dls\n",
    "        self.loss_func = loss_func\n",
    "        self.metrics = metrics\n",
    "        \n",
    "        self.init()\n",
    "        self.opt = BasicOptim2D(self.net, lr=1e-3)\n",
    "        \n",
    "    def init_weights(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "    \n",
    "    def init(self):\n",
    "        self.net.apply(self.init_weights)\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        for d in self.dls.train:\n",
    "            \n",
    "            x, y = d[0]\n",
    "            \n",
    "            preds = self.net(x)\n",
    "        \n",
    "            input_ = preds.unsqueeze(1)\n",
    "            \n",
    "            loss = self.loss_func(preds, y)\n",
    "            loss.backward()\n",
    "    \n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "                \n",
    "    def train_model(self, epochs):\n",
    "        for i in range(epochs):\n",
    "            self.train_epoch()\n",
    "            print(self.validate_epoch())\n",
    "    \n",
    "    def validate_epoch(self):\n",
    "        accs = [self.metrics(self.net(ds[0][0]), ds[0][1]) for ds in self.dls.valid]\n",
    "        return round(torch.stack(accs).mean().item(), 4)\n",
    "\n",
    "    def fit(self, epochs = 10):\n",
    "        self.train_model(epochs)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2599\n",
      "0.2599\n",
      "0.2599\n",
      "0.2599\n",
      "0.2599\n",
      "0.2598\n",
      "0.2598\n",
      "0.2598\n",
      "0.2594\n",
      "0.2594\n"
     ]
    }
   ],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28, 30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30, 10)\n",
    ")\n",
    "\n",
    "def cross_entropy_loss(preds, targets):\n",
    "    preds = preds.softmax(dim=0)\n",
    "\n",
    "    loss = -(targets * preds.log()).sum() / len(preds)\n",
    "    return loss\n",
    "\n",
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds > 0.5) == yb\n",
    "    return correct.float().mean()\n",
    "\n",
    "l = Learner2D(dls = ds, net = simple_net, loss_func = cross_entropy_loss, metrics=batch_accuracy)\n",
    "\n",
    "l.fit(epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All mnist numbers using full fastai APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = DataBlock(blocks = (ImageBlock(cls=PILImageBW),CategoryBlock),\n",
    "                  get_items = get_image_files,\n",
    "                  splitter = GrandparentSplitter(),\n",
    "                  get_y = parent_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = mnist.datasets(untar_data(URLs.MNIST))\n",
    "\n",
    "import pdb; pdb.set_trace()\n",
    "\n",
    "print(dsets.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
